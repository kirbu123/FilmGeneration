{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import usefull libs","metadata":{"id":"CrSbbyks4XFk"}},{"cell_type":"code","source":"!pip install setuptools-rust","metadata":{"id":"BdXAslJvkYL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers==2.5.1","metadata":{"id":"Tl02sWTZjdML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade diffusers","metadata":{"id":"FROa_dV-iQp_","executionInfo":{"status":"ok","timestamp":1696184595160,"user_tz":-180,"elapsed":1651,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"e692344c-5d2f-48e6-c118-feb8019dbcb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install img2dataset","metadata":{"id":"KvCufpvAM1I0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"id":"qiWlcZ17M3F6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport time\nfrom datetime import datetime\nfrom tqdm import tqdm\nimport pandas as pd\nfrom google.colab import drive\nimport os\nimport math\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.manifold import TSNE\nimport numpy as np\nfrom sklearn import svm\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, f1_score\nfrom sklearn.model_selection import cross_val_score, train_test_split, RepeatedKFold, KFold\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport csv\nfrom urllib.request import urlopen\nimport multiprocessing\nimport wandb\nimport tarfile","metadata":{"id":"5fEQ7bq_4LVc","executionInfo":{"status":"ok","timestamp":1696184657349,"user_tz":-180,"elapsed":8485,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correct dataset loading by API","metadata":{"id":"wwtiHYHoMZaI"}},{"cell_type":"code","source":"# Making directory for url-list files\n!mkdir -p laion-high-resolution && cd laion-high-resolution\n# Downloading files from url\n!for i in {00000..00001}; do wget -P laion-high-resolution/ https://huggingface.co/datasets/laion/laion-high-resolution/resolve/main/part-$i-5d6701c4-b238-4c0a-84e4-fe8e9daea963-c000.snappy.parquet; done","metadata":{"id":"OVr_dTWsMm4n","executionInfo":{"status":"ok","timestamp":1696083805600,"user_tz":-180,"elapsed":2316,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"1ab1630b-d429-434e-b567-791e42c29ef8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loginig in wandb\nwandb.login()","metadata":{"id":"KSBZIclhMufV","executionInfo":{"status":"ok","timestamp":1696083862942,"user_tz":-180,"elapsed":47371,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"899ba49a-9d4c-42af-dba8-524846180328"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!rm -rf /content/laion-high-resolution-output","metadata":{"id":"lqtBnP-ZR3iu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Downloading .tar by url-list files from created directory\n# Do not forget to stop running after completing the load\n!img2dataset --url_list laion-high-resolution --input_format \"parquet\"\\\n         --url_col \"URL\" --caption_col \"TEXT\" --output_format webdataset\\\n           --output_folder laion-high-resolution-output --processes_count 16 --thread_count 64 --image_size 1024\\\n            --resize_only_if_bigger=True --resize_mode=\"keep_ratio\" --skip_reencode=True \\\n             --save_additional_columns '[\"similarity\",\"hash\",\"punsafe\",\"pwatermark\",\"LANGUAGE\"]' --enable_wandb True","metadata":{"id":"hJ4QZ3QdM_FG","executionInfo":{"status":"ok","timestamp":1696084041750,"user_tz":-180,"elapsed":156813,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"2ae1cb7c-8649-49b8-fd29-a7c95d34b330"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dataset directory for ready files\n!mkdir -p dataset","metadata":{"id":"SYTs4ZeYN8wQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function encode .tar by the path\n# Files will encode in /content/, do not forget to use next func\ndef UnboxTar(tar_path = \"/content/laion-high-resolution-output/00000.tar\"):\n  try:\n      tar = tarfile.open(tar_path)\n      tar.extractall()\n      tar.close()\n  except Exception:\n      print('Error')","metadata":{"id":"CE9egN4nN_OD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UnboxTar()","metadata":{"id":"jPGwOdJ7OYqq","executionInfo":{"status":"ok","timestamp":1696084056186,"user_tz":-180,"elapsed":377,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"1038d186-57e7-4eb5-f106-569f4bcefda7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move all files from /content/ to file_path directory\ndef ReloadAllToFrom(file_path = 'dataset', directory = '/content/'):\n  !mkdir -p {file_path}\n  for filename in os.listdir(directory):\n    # os.path.join соединяет путь до директории и имя файла\n    path = os.path.join(directory, filename)\n    # os.path.isfile проверяет, является ли путь файлом (а не папкой)\n    if os.path.isfile(path):\n      !mv {path} {path[:path.rfind('/') + 1] + file_path + '/' + path[path.rfind('/') + 2:]}","metadata":{"id":"EHT2k0GHOdMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move image files from /content/ to file_path directory\ndef ReloadImgFromTo(from_path = 'dataset', to_path = 'dataset_images'):\n  !mkdir -p {to_path}\n  for filename in os.listdir(from_path):\n    # os.path.join соединяет путь до директории и имя файла\n    path = os.path.join(from_path, filename)\n    # os.path.isfile проверяет, является ли путь файлом (а не папкой)\n\n    if os.path.isfile(path):\n      if path[path.find('.') + 1:] == 'jpg' or path[path.find('.') + 1:] == 'png' or path[path.find('.') + 1:] == 'jpeg':\n        !mv {path} {to_path + '/' + path[path.rfind('/') + 2:]}","metadata":{"id":"5aTrb-OnPw8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ReloadAllToFrom()","metadata":{"id":"JPc1ZKLHOxcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ReloadImgFromTo()","metadata":{"id":"Mz5UeN4aVajl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result we have directory (named dataset in default situation) with text, images and describes from the dataset.","metadata":{"id":"j75UKA2fPEs3"}},{"cell_type":"markdown","source":"## Load dataset by parsing (bad alternative)","metadata":{"id":"2ELbAk-T4g4q"}},{"cell_type":"markdown","source":"Make data directory, go there","metadata":{"id":"r--V3fehXls7"}},{"cell_type":"code","source":"!mkdir laion-high-resolution && cd laion-high-resolution","metadata":{"id":"DzkuM9d44VvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for loading 100 rows of dataset from the url\n# Param filtering indicate filtering of data by languages (langs) when it is filtering = True\n# Param filter_lang sorts data from all langs except filter_lang\n# Param file_name sets file_name + .csv\ndef LoadLaionDataset(filtering = False, filter_lang = '', load_csv = False, file_name = 'dataset', url = 'https://huggingface.co/datasets/laion/laion-high-resolution/viewer/default/train'):\n  # Created an URL object in url\n  # Create object page\n  page = requests.get(url)\n  # parser-lxml = Change html to Python friendly format\n  # Obtain page's information\n  soup = BeautifulSoup(page.text, 'lxml')\n  # Obtain information from tag <table>\n  table = soup.find('table', attrs={\"class\": \"w-full table-auto rounded-lg font-mono text-xs text-gray-900\"})\n  # Obtain every title of columns with tag <th>\n  headers = []\n  for i in table.find_all('th'):\n    title = i.text\n    headers.append(title[:title.find('\\n')])\n  # Create a dataframe\n  df = pd.DataFrame(columns = headers)\n  # Create a for loop to fill mydata\n  for j in table.find_all('tr')[1:]:\n    row_data = j.find_all('td')\n    row = [i.text[:i.text.find('\\n')] for i in row_data]\n    for i in range(len(row)):\n      row[i] = row[i][row[i].find('\"') + 1: row[i].rfind('\"')]\n    length = len(df)\n    df.loc[length] = row\n  # Filtering by languages\n  if filtering:\n    df = df[df['LANGUAGE'] == filter_lang]\n  # Loading .csv\n  if load_csv:\n    df.to_csv ('/content/laion-high-resolution/' + str(file_name) + '.csv', index= False )\n  return df","metadata":{"id":"i0VsqEJZU2mn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = LoadLaionDataset(load_csv = True)","metadata":{"id":"Jy5_IVxaWOTc","executionInfo":{"status":"error","timestamp":1696034954009,"user_tz":-180,"elapsed":672,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"54d8ed7c-f2c1-4128-90ff-cced93abbe2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"r_UOk-M6ZmdL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upgrade of dataset loading function","metadata":{"id":"hr2iqwl1ETGM"}},{"cell_type":"code","source":"# Param frames_count sets count of loading url pages\n# Other params are same eith previous function\ndef LoadData(frames_count = 1, filtering = False, filter_lang = '', load_csv = False, file_name = 'dataset', based_url = 'https://huggingface.co/datasets/laion/laion-high-resolution/viewer/default/train'):\n  # DataFrame list\n  df_list = list()\n  # Updating df_list by loading .csv by url\n  for i in tqdm(range(frames_count)):\n    df_list.append(LoadLaionDataset(filtering, filter_lang, load_csv = False, url = based_url + '?p=' + str(i)))\n  # concating df_list to one big DataFrame\n  result_df = pd.concat(df_list)\n  X = result_df[['TEXT', 'LANGUAGE']].to_numpy()\n  y = result_df['URL'].to_numpy()\n  return result_df, list([X, y])","metadata":{"id":"SQVPf5AuEg03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, dataset = LoadData(frames_count = 1)","metadata":{"executionInfo":{"elapsed":3846,"status":"ok","timestamp":1695927093921,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"5dfp1h5KGqWS","outputId":"391bd778-0741-4745-d60c-73d9cfe6f400"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"executionInfo":{"elapsed":562,"status":"ok","timestamp":1695927104227,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"3kpToVQRSPZK","outputId":"c4eb8615-a741-4117-860f-fb6f4d140a18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"executionInfo":{"elapsed":481,"status":"ok","timestamp":1695927107413,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"pWK0dcw6SQjC","outputId":"fd566324-03c2-4a9f-a902-3041434acf9e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0][0]","metadata":{"executionInfo":{"elapsed":407,"status":"ok","timestamp":1695927111388,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"3jPyNxT3QuqS","outputId":"fde6653c-e0ce-4259-a1cd-92868751798f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KFold sampling on train-test split\n\n","metadata":{"id":"mbg4lSxdSTAJ"}},{"cell_type":"code","source":"# This func makes KFold from Sklearn more convinient to out task\ndef KFoldSampling(dataset, nsplits):\n  # X, y split from dataset\n  X, y = dataset[0], dataset[1]\n  kf = KFold(n_splits = nsplits)\n  kf.get_n_splits()\n  # list of indicies of KFold\n  result = list()\n  for i, (train_index, test_index) in tqdm(enumerate(kf.split(X))):\n    # Appending train-test indicies ro result list\n    result.append(np.array([train_index, test_index]))\n  return np.array(result)","metadata":{"id":"_HPTFcFhSSdy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KFoldSampling(dataset, nsplits=2)","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1695927125172,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"WOnq2QigUaxH","outputId":"ceee5f2f-81b7-4f8a-f730-6dee30a52322"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset transform from url to image","metadata":{"id":"EcUMMudIU7Nf"}},{"cell_type":"code","source":"# Function for loading image\ndef LoadImageMulti(url, queue):\n  response = requests.get(url)\n  img = Image.open(BytesIO(response.content))\n  queue.put(img)\n\n# Safe loading of image with time limit\n\ndef LineStop(target, arg, time_limit = 10):\n  queue = multiprocessing.Queue()\n  p = multiprocessing.Process(target=target, args=(arg, queue))\n  p.start()\n  p.join(time_limit)\n  if p.is_alive():\n    print('ABORT')\n    # Terminate\n    p.terminate()\n    return\n  return queue.get()\n\nLineStop(LoadImageMulti, 'https://mmedia.ozone.ru/multimedia/1018085734.JPG')","metadata":{"executionInfo":{"elapsed":10806,"status":"ok","timestamp":1695927147605,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"iX9TKUcZpoKb","outputId":"252d239b-e0a5-4899-df95-59925b32470d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def DatasetTransform(dataset, image_dir = '', time_limit = 10, all_time_limit = 1000):\n  # Making directory for dataset\n  if image_dir:\n    if image_dir[len(image_dir) - 1] == '/':\n      image_dir = image_dir[:len(image_dir) - 1]\n    os.environ[\"DIRECTORY_NAME\"] = image_dir\n    !mkdir -p ${DIRECTORY_NAME}\n  # Making X, y from dataset\n  X = dataset[0]\n  y = dataset[1]\n  # Making result lists\n  result_y = list()\n  result_X = list()\n  # Start time\n  start_time = datetime.now()\n\n  for i, url in enumerate(tqdm(y)):\n    # All exceptions are ignored\n    try:\n      # Load image\n      response = requests.get(url)\n      img = Image.open(BytesIO(response.content))\n      if image_dir:\n        print(image_dir + '/image_' + str(i) + '.jpg')\n        img.save(image_dir + '/image_' + str(i) + '.jpg')\n    except Exception:\n      continue\n    # Appending numpy image\n    result_y.append(np.array(img))\n    result_X.append(X[i])\n    # Checking time break\n    if (datetime.now() - start_time).seconds > all_time_limit:\n      print('Time break')\n      return list([np.array(result_X), np.array(result_y)])\n  return list([np.array(result_X), np.array(result_y)])","metadata":{"id":"sP2zg_lsU2pX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DatasetTransform(dataset, image_dir='/content/data_images', all_time_limit = 30)","metadata":{"executionInfo":{"elapsed":35723,"status":"ok","timestamp":1695927224092,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"5WPYGpUcVuFk","outputId":"933af224-dbc7-410c-b3f5-3dda9969d7cc","_kg_hide-input":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SDXL PART","metadata":{"id":"5cEeW1DBumXj"}},{"cell_type":"markdown","source":"## Loading packages","metadata":{"id":"1Mb1iv6QiwCC"}},{"cell_type":"markdown","source":"Downloading & Importing smth","metadata":{"id":"0VqbP3u7gIoJ"}},{"cell_type":"code","source":"!pip install --upgrade safetensors","metadata":{"id":"1PUIxyOj3piZ","executionInfo":{"status":"ok","timestamp":1696184785790,"user_tz":-180,"elapsed":4507,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"e2dc160c-b5ed-46a8-d0cf-008dc00bf25b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"8tVVX_9d6aqt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"id":"qy-bqc5iedmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade diffusers","metadata":{"id":"N3S24HYUgaX5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import snapshot_download\nfrom diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline","metadata":{"id":"-0FYaCf4gL2H","executionInfo":{"status":"ok","timestamp":1696184881962,"user_tz":-180,"elapsed":3082,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"b4cee52a-7097-4d37-9167-c566cf4231a4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Refactoring directory by matching images","metadata":{"id":"KeLFWUJSi1f8"}},{"cell_type":"code","source":"def MatchImagesDir(directory = '/content/data_images', target_dir = '/content/matched_images'):\n  list_img = list()\n  for filename in os.listdir(directory):\n    # os.path.join соединяет путь до директории и имя файла\n    path = os.path.join(directory, filename)\n    # os.path.isfile проверяет, является ли путь файлом (а не папкой)\n\n    if os.path.isfile(path):\n      if path[path.find('.') + 1:] == 'jpg' or path[path.find('.') + 1:] == 'png' or path[path.find('.') + 1:] == 'jpeg':\n        list_img.append(path)\n  for i in range(len(list_img) - 1):\n    # Read images\n    img_left = Image.open(list_img[i])\n    img_right = Image.open(list_img[i + 1])\n    # Reading sizes\n    width_left, height_left = img_left.size\n    width_right, height_right = img_right.size\n    # Counting new sizes\n    result_width = width_left + width_right\n    result_height = max(height_left, height_right)\n    # Making result image\n    result = Image.new('RGB', (result_width, result_height))\n    # Refactoring result image\n    result.paste(im=img_left, box=(0, 0))\n    result.paste(im=img_right, box=(width_left, 0))\n    # Save result image\n    result.save(target_dir + '/matched' + str(i) + '.jpg')","metadata":{"id":"qSnATIewj8Ol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MatchImagesDir()","metadata":{"id":"bxBJkIprmURM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SDXL with Finetuning","metadata":{"id":"HoU84BRlS6d7"}},{"cell_type":"markdown","source":"Example pictures dataset","metadata":{"id":"EO2lkI4ad1mk"}},{"cell_type":"code","source":"local_dir = \"./dog\"\nsnapshot_download(\n    \"diffusers/dog-example\",\n    local_dir=local_dir, repo_type=\"dataset\",\n    ignore_patterns=\".gitattributes\",\n)","metadata":{"executionInfo":{"elapsed":2406,"status":"ok","timestamp":1696084344825,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"},"user_tz":-180},"id":"SBhGla9LVjB9","outputId":"a2328296-a9c8-4c35-d1d0-a9369f2d6231"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title 🤗 AutoTrain DreamBooth\n#@markdown In order to use this colab\n#@markdown - upload images to a folder named `images/`\n#@markdown - choose a project name if you wish\n#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n#@markdown - add huggingface information (token and repo_id) if you wish to push trained model to huggingface hub\n#@markdown - update hyperparameters if you wish\n#@markdown - click `Runtime > Run all` or run each cell individually\n\n!pip install -U autotrain-advanced > install_logs.txt\n!autotrain setup > setup_logs.txt","metadata":{"id":"28DJIS5KemRP","executionInfo":{"status":"ok","timestamp":1696084541945,"user_tz":-180,"elapsed":163070,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"b0bd2ba4-2058-4521-9c27-28e26b090666"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@markdown ---\n#@markdown #### Project Config\nproject_name = 'fine_tuned_model' # @param {type:\"string\"}\ndataset_dir = '/content/matched_images' # @param {type: \"string\"}\nmodel_name = 'runwayml/stable-diffusion-v1-5' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\nprompt = 'combination of prompts' # @param {type: \"string\"}\n\n\n#@markdown ---\n#@markdown #### Push to Hub?\n#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n#@markdown You can find your token here: https://huggingface.co/settings/tokens\npush_to_hub = False # @param [\"False\", \"True\"] {type:\"raw\"}\nhf_token = \"hf_XXX\" #@param {type:\"string\"}\nrepo_id = \"username/repo_name\" #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown #### Hyperparameters\nlearning_rate = 1e-3 # @param {type:\"number\"}\nnum_steps = 20 #@param {type:\"number\"}\nbatch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\ngradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\nresolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\nuse_8bit_adam = True # @param [\"False\", \"True\"] {type:\"raw\"}\nuse_xformers = True # @param [\"False\", \"True\"] {type:\"raw\"}\nuse_fp16 = True # @param [\"False\", \"True\"] {type:\"raw\"}\ntrain_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\ngradient_checkpointing = True # @param [\"False\", \"True\"] {type:\"raw\"}\n\nos.environ[\"PROJECT_NAME\"] = project_name\nos.environ[\"DATASET_DIR\"] = dataset_dir\nos.environ[\"MODEL_NAME\"] = model_name\nos.environ[\"PROMPT\"] = prompt\nos.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\nos.environ[\"HF_TOKEN\"] = hf_token\nos.environ[\"REPO_ID\"] = repo_id\nos.environ[\"LEARNING_RATE\"] = str(learning_rate)\nos.environ[\"NUM_STEPS\"] = str(num_steps)\nos.environ[\"BATCH_SIZE\"] = str(batch_size)\nos.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\nos.environ[\"RESOLUTION\"] = str(resolution)\nos.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\nos.environ[\"USE_XFORMERS\"] = str(use_xformers)\nos.environ[\"USE_FP16\"] = str(use_fp16)\nos.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\nos.environ[\"GRADIENT_CHECKPOINTING\"] = str(gradient_checkpointing)","metadata":{"id":"pVLFdZxset7N","executionInfo":{"status":"ok","timestamp":1696184774960,"user_tz":-180,"elapsed":3,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!autotrain dreambooth \\\n--model ${MODEL_NAME} \\\n--project-name ${PROJECT_NAME} \\\n--image-path ${DATASET_DIR} \\\n--prompt \"${PROMPT}\" \\\n--resolution ${RESOLUTION} \\\n--batch-size ${BATCH_SIZE} \\\n--num-steps ${NUM_STEPS} \\\n--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n--lr ${LEARNING_RATE} \\\n$( [[ \"$USE_FP16\" == \"True\" ]] && echo \"--fp16\" ) \\\n$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n$( [[ \"$GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--gradient-checkpointing\" ) \\\n$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN} --repo-id ${REPO_ID}\" )","metadata":{"id":"Y8Ppamp8fC03","executionInfo":{"status":"ok","timestamp":1696086718277,"user_tz":-180,"elapsed":333234,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"0196f982-2d63-4858-aa71-5f87ef85f931"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ImageFromPrompt(prompt, weight_name=\"pytorch_lora_weights.safetensors\", project_name=project_name, model=model_name):\n  prj_path = \"/content/\" + str(project_name)\n  pipe = DiffusionPipeline.from_pretrained(\n      model,\n      torch_dtype=torch.float16,\n  )\n  pipe.to(\"cuda\")\n  pipe.load_lora_weights(prj_path, weight_name=weight_name)\n\n  refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n      \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n      torch_dtype=torch.float16,\n  )\n  refiner.to(\"cuda\")\n\n  seed = 42\n  generator = torch.Generator(\"cuda\").manual_seed(seed)\n  image = pipe(prompt=prompt, generator=generator).images[0]\n  image_upgrade = refiner(prompt=prompt, generator=generator, image=image).images[0]\n  return image, image_upgrade","metadata":{"id":"FrthL2ybNF1a","executionInfo":{"status":"ok","timestamp":1696186014631,"user_tz":-180,"elapsed":699,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, img_upgrade = ImageFromPrompt('combination of prompts: photo of Leo Messi/photo of Cristiano Ronaldo', weight_name='model.safetensors')","metadata":{"id":"1LS95S18OKKD","executionInfo":{"status":"ok","timestamp":1696186281945,"user_tz":-180,"elapsed":263206,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"9e77ba54-e529-495b-d60b-904ac4750193"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img","metadata":{"id":"3dzYR-Z3lN0b","executionInfo":{"status":"ok","timestamp":1696186300683,"user_tz":-180,"elapsed":3226,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"5c98d4f4-cda2-4160-fccc-d454d060b30f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_upgrade","metadata":{"id":"eYie8UGCPv9o","executionInfo":{"status":"ok","timestamp":1696186313435,"user_tz":-180,"elapsed":3442,"user":{"displayName":"Кирилл Бунин","userId":"06141949029361654961"}},"outputId":"0734c5e2-511d-4500-d421-e7607da30643"},"execution_count":null,"outputs":[]}]}